"""
âœ…å·²ä¸Šçº¿	ç‰›å¯¼èˆª - å®ç”¨å·¥å…·å¯¼èˆª	http://ziliao6.com/
âœ…å·²ä¸Šçº¿	é«˜æ•ˆæœç½— - ç²¾å‡†çš„èŒä¸šå¯¼èˆª	http://gaoxiaosouluo.cn/
âœ…å·²ä¸Šçº¿	å–å®¶å¤§å…¨ - æœ€å…¨å–å®¶å¯¼èˆª	http://maijiadaquan.com/
âœ…å·²ä¸Šçº¿	å¹¿å‘Šäººå¯¼èˆª - å¹¿å‘Šæ²¡é—¨	https://adnodoor.com/nav/

âœ…å·²ä¸Šçº¿	åŸŸåè´­ä¹°&åŸŸåå•†åœº&è¡Œä¸šå¯¼èˆª	http://www.yichushou.com/

âœ…å·²ä¸Šçº¿	DreamThere - æ¢¦æƒ³å¯¼èˆª	https://nav.dreamthere.com/

âœ…å·²ä¸Šçº¿	æ¨èçŸ­è§†é¢‘ - ç½‘çº¢çŸ­è§†é¢‘å¯¼èˆª	https://wx.dreamthere.com/
âœ…å·²ä¸Šçº¿	ç‹¼ç‰Œå·¥ä½œç½‘å€å¯¼èˆª	https://www.volf.club/
âœ…å·²ä¸Šçº¿	JKnearå¯¼èˆª - å»ºç­‘ç»“æ„è®¾è®¡å¯¼èˆª	http://jk.jknear.com:777/
âœ…å·²ä¸Šçº¿	site navigation â€“ QAOZEN	https://qaozen.com/nav/
âœ…å·²ä¸Šçº¿	äº¬ä¸œè¿è¥ç½‘å€å¯¼èˆª	http://miyue1980.com/
âœ…å·²ä¸Šçº¿	å¿«å¯¼èˆª - ç®€å•çš„ç½‘å€å¯¼èˆªå¤§å…¨	https://wukandy.cn/
âœ…å·²ä¸Šçº¿	ShareHub - èµ„æºå’Œå·¥å…·çš„é›†åˆ	https://www.gezhipu.com/cn/index.html
âœ…å·²ä¸Šçº¿	å–µå¸•æ–¯ - å–µå¸•æ–¯å¯¼èˆªé¡µ	http://naspro.cc/
âœ…å·²ä¸Šçº¿	æˆ‘çš„æ”¶è—å¤¹ - ä¸ªäººç½‘å€å¯¼èˆªç«™	https://www.kukiliao.com/
âœ…å·²ä¸Šçº¿	tool - wxuegao	http://tool.wxuegao.com/
âœ…å·²ä¸Šçº¿	vv.lc - ç½‘å€å¯¼èˆª	http://vv.lc/
âœ…å·²ä¸Šçº¿	ç¨‹åºå‘˜ç½‘å€å¯¼èˆª - hujiangtao	https://web.hujiangtao.cn/
âœ…å·²ä¸Šçº¿	é…¸å¥¶ - å¹¿å‘Šè¿è¥ä»ä¸šè€…ç±»åˆ«å¯¼èˆª	é…¸å¥¶ - ä¸“æ³¨å¹¿å‘Šè¿è¥ä»ä¸šè€…ç±»åˆ«å¯¼èˆª
âœ…å·²ä¸Šçº¿	æµ®ç”Ÿè®ºå› - å¿µå¿µä¸å¿˜ï¼Œå¿…æœ‰å›å“	æµ®ç”Ÿè®ºå› - å¿µå¿µä¸å¿˜ï¼Œå¿…æœ‰å›å“
âœ…å·²ä¸Šçº¿	Pandaroll.cn ç½‘å€å¯¼èˆª	Pandaroll.cn ç½‘å€å¯¼èˆª
ğŸ•—å¼€å‘ä¸­	QAdoc - æµ‹è¯•å·¥ä½œè€…å¯¼èˆª	http://nav.qadoc.org/cn/index.html
ğŸ•—å¼€å‘ä¸­	t.hiihi	http://t.hiihi.cn/
ğŸ•—å¼€å‘ä¸­	zou0	http://www.zou0.com/cn/index.html
ğŸ•—å¼€å‘ä¸­	Matrix Navigation	Matrix Navigation -
ğŸ•—å¼€å‘ä¸­	PMGEEK	http://pmgeek.net/
ğŸ•—å¼€å‘ä¸­	lerso.cn	http://lerso.cn/
ğŸ•—å¼€å‘ä¸­	dh.wdj.pw	WebStack.cc - è®¾è®¡å¸ˆç½‘å€å¯¼èˆª
ğŸ•—å¼€å‘ä¸­	wukandy.cn	https://wukandy.cn/


"""
from urllib.request import urlopen
from bs4 import BeautifulSoup

def getHTML(url):
	html = urlopen(url)
	bs = BeautifulSoup(html.read(), features="html.parser")
	return bs


def getData(url):
	bs = getHTML(url)
	titleContent = bs.head.title.text
	#print(bs)
	body = bs.find_all("body")[0]

	cards = body.findAll("div", {"class": "col-sm-3"})
	print("æ•°é‡ï¼š" + str(len(cards)))

	data = []
	for one in cards:
		website = {}
		webUrlDiv = one.findAll("div", {"class": "xe-widget xe-conversations box2 label-info"})
		webUrl = webUrlDiv[0].attrs["data-link"]

		# print(one)
		webName = one.strong.text
		webInfo = one.findAll("p", {"class": "overflowClip_2"})[0].text.replace(' ','').replace('\n','')
		website["webName"] = webName
		website["webInfo"] = webInfo
		website["webUrl"] = webUrl
		print(website)
		data.append(website)
		print("*"*10)
	return data


if __name__ == "__main__":



	data = getData("http://maijiadaquan.com/")
	print(data)

	import csv
	csvFile = open("./taobao.csv", 'w+',  encoding="utf-8", newline='')
	writer = csv.writer(csvFile)
	writer.writerow(('åºå·', 'ç½‘ç«™åç§°', 'ç½‘ç«™æè¿°', 'ç½‘å€', 'æ¥æº'))
	i = 1
	for one in data:
		writer.writerow((i, one["webName"], one["webInfo"], one["webUrl"], "http://maijiadaquan.com/"))
		i = i + 1
	csvFile.close()